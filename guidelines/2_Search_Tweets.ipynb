{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Tweets\n",
    "\n",
    "Twitter forms a rich source of information for researches interested in study 'the public conversation' about any thinkable topic. \n",
    "\n",
    "In order to find Tweets related to the topic of your interest, you may search tweets using two endpoints, **Recent search** and **full-archive search**. A recent search will yield Tweets from the past 7 days, while the full-archive search goes back to the first public Tweet from March 2006. \n",
    "\n",
    "To filter tweets, no matter which endpoint you are using, you need to provide a **search query**.\n",
    "According to Twitter website, \"These search queries are created with a set of operators that match on Tweet and user attributes, such as message keywords, hashtags, and URLs. Operators can be combined into queries with boolean logic and parentheses to help refine the queries matching behavior.\" More on these queries later.\n",
    "\n",
    "In this guideline we will describe how you can use the [tweet_collector repository](https://github.com/UtrechtUniversity/tweet_collector) to extract tweets for *your* research!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The tweet_collector repository\n",
    "The tweet_collector repository consists of three main folders; the config, guidelines, and src folder. \n",
    "\n",
    "The search_tweet.py script can be found in de `src` foler. The script takes three arguments: \n",
    "1. `--credential-file <CREDENTIAL_FILENAME>`\n",
    "2. `--config-file <CONFIG_FILENAME>` \n",
    "3. `--env-overwrite <BOOLEAN>` \n",
    "\n",
    "The credential and configuration files are requirements for running the script, and can be found in the `config` folder. The `--env-overwrite` argument overwrites YAML-parsed credentials with any set environment variables (default is TRUE).\n",
    "\n",
    "Finally, guidelines on how to apply for an Academic Research application, are stored in the `guidelines` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "\n",
    "### 1. Credential file\n",
    "The credential file holds your Twitter credentials. The simplest credential file should look like this:\n",
    "\n",
    "```\n",
    "search_tweets_v2:\n",
    "  endpoint:  https://api.twitter.com/2/tweets/search/...\n",
    "  consumer_key: ek...\n",
    "  consumer_secret: hy...\n",
    "  bearer_token: AA...\n",
    "```\n",
    "\n",
    "By default, this library expects this file at `~/.twitter_keys.yaml`, but you can pass the relevant location as needed with the `--credential-file <CREDENTIAL_FILENAME>` flag for the command-line app.\n",
    "\n",
    "#### 1.A. Recent Search\n",
    "To execute a recent search, the endpoint specification in the credential file needs to be set to 'recent'. The ‘recent’ search endpoint provides Tweets from the **past 7 days**.\n",
    "\n",
    "```\n",
    "search_tweets_v2:\n",
    "  endpoint:  https://api.twitter.com/2/tweets/search/recent\n",
    "  consumer_key: ek...\n",
    "  consumer_secret: hy...\n",
    "  bearer_token: AA...\n",
    "```\n",
    "\n",
    "#### 1.B. Full-archive Search\n",
    "To execute a full-archive search, the endpoint specification in the credential file needs to be set to 'all'. The ‘all’ search endpoint, launched in January 2021 as part of the ‘academic research’ tier of Twitter API v2 access, provides access to all publicly avaialble Tweets posted **since March 2006**.\n",
    "\n",
    "```\n",
    "search_tweets_v2:\n",
    "  endpoint:  https://api.twitter.com/2/tweets/search/all\n",
    "  consumer_key: ek...\n",
    "  consumer_secret: hy...\n",
    "  bearer_token: AA...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Configuration file\n",
    "The configuration file (i.e., `api_config.config`) contains all parameters. Placing all paramters into one file is far easier to use than the command-line args version. If a valid configuration file is found, all arguments will be populated from there. N.B. Remaining command-line arguments will overrule arguments found in the config file (if `--env-overwrite` is not set to FALSE).\n",
    "\n",
    "An example of such a config-file:\n",
    "\n",
    "```\n",
    "[search_rules]\n",
    "start_time = 2021-05-01\n",
    "end_time = 2021-06-01\n",
    "query = (happy or happiness) lang:en -birthday -is:retweet has:hashtags\n",
    "tweet_fields = id,created_at,text,public_metrics\n",
    "user_fields = description\n",
    "expansions=author_id\n",
    "\n",
    "[search_params]\n",
    "results_per_call = 10\n",
    "max_tweets = 10\n",
    "output_format = r\n",
    "\n",
    "[output_params]\n",
    "save_file = True\n",
    "filename_prefix = output_new\n",
    "results_per_file = 10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.A. Search rules\n",
    "In the config-file you can enter all search rules necessary for your research. \n",
    "\n",
    "To filter Tweets based on time/id, use one or more of the following search rules:\n",
    "```\n",
    "start_time = <Start of datetime window, format ‘YYYY-mm-DDTHH:MM’> \n",
    "end_time = <End of datetime window, format ‘YYYY-mm-DDTHH:MM’>\n",
    "since_id = <Tweet ID, will start search from Tweets after this one>\n",
    "until_id = <Tweet ID, will end search from Tweets before this one>\n",
    "```\n",
    "\n",
    "To include extra information to your results, you can use various 'fields' rules (see [this page](https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/user) for more info):\n",
    "```\n",
    "tweet_fields = <A comma-delimited list of Tweet JSON attributes to include in endpoint responses>\n",
    "place_fields = <A comma-delimited list of Twitter Place JSON attributes to include in endpoint responses>\n",
    "user_fields = <A comma-delimited list of User JSON attributes to include in endpoint responses>\n",
    "media_fields = <A comma-delimited list of media JSON attributes to include in endpoint responses>\n",
    "poll_fields = <A comma-delimited list of Twitter Place JSON attributes to include in endpoint responses>\n",
    "```\n",
    "Example: if you want to know more about the geographical information of the filtered tweets, you can include `geo_fields = country,country_code`.\n",
    "\n",
    "To be able to include (one of) these extra fields listed above, you also need to provide the 'expansions' rule:\n",
    "```\n",
    "expansions = <A comma-delimited list of expansions. Specified expansions results in full objects in the ‘includes’ response object>\n",
    "```\n",
    "Example: if you wish to include `geo_fields = country,country_code` you have to include `expansions = geo.place_id`. While the place ID will be located in the Tweet object, you will find this ID and all additional place fields in the 'includes' data object. (Please see [this page](https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/user) for field-expansions pairs.)\n",
    "\n",
    "Finally, the most import rule, is your search query:\n",
    "```\n",
    "query = <Search query>\n",
    "```\n",
    "\n",
    "##### Search query\n",
    "In the query specification, you enter how you wish to filter Tweets. Commonly used arugments are:\n",
    "* `<key_word1> OR <key_word2>` (look for Tweets including either word1 or word2)\n",
    "* `lang:<lang>` (only receive Tweets that are in specific langauge. Example, lang:en selects only English Tweets)\n",
    "* `-is:<type>` ('-' is a negation operator; excludes certain types of Tweets. Example, -is:retweet exclused retweets, leaving only original Tweets) \n",
    "* `-<key_word>` ('-' is a negation operator; excludes Tweets with key_word in it)\n",
    "* `has:<prop>` (matches Tweets that have specific property. Example, has:geo selectes Tweets with Tweet-specific geolocation data provided by the Twitter user)\n",
    "\n",
    "Hence, if you want to look for original Tweets in English related to happy or happiness containing at least one hashtag, but are not related to birthday whishes, we write:\n",
    "```\n",
    "query = (happy or happiness) lang:en -birthday -is:retweet has:hashtags\n",
    "```\n",
    "\n",
    "To get an extensive overview of how you can structure a query, have a look [here](https://developer.twitter.com/en/docs/twitter-api/tweets/counts/integrate/build-a-query). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.B. Search parameters\n",
    "In the config-file you can enter all search parameters necessary for your research. \n",
    "\n",
    "Here are some examples:\n",
    "```\n",
    "[search_params]\n",
    "results_per_call = <Number of results to return per call (default 10; max 100)>\n",
    "max_tweets = <Maximum number of Tweets to return for this session of requests>\n",
    "max_pages = <Maximum number of pages/API calls to use for this session>\n",
    "output_format = <Set output format*>\n",
    "extra_headers = <JSON-formatted str representing a dict of additional HTTP request headers>\n",
    "```\n",
    "*= ‘r’ Unmodified API [R]esponses. (default). ‘a’ [A]tomic Tweets: Tweet objects with expansions inline. ‘m’ [M]essage stream: Tweets, expansions, and pagination metadata as a stream of messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.C. Output parameters\n",
    "In the config-file you can enter all output parameters necessary for your research. \n",
    "\n",
    "Here are some examples:\n",
    "```\n",
    "[output_params]\n",
    "save_file = True\n",
    "filename_prefix = <prefix for the filename where tweet json data will be stored>\n",
    "results_per_file = <Maximum tweets to save per file>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running script\n",
    "After you've filled in your credentials in the `.twitter_keys.yaml` and entered all parameters needed for your Twitter search in the `api_config.config` file, you can run the script in the command line with the following code:\n",
    "\n",
    "```\n",
    "cd tweet_collector\n",
    "python3 src/search_tweet.py --credential-file \"config/.twitter_keys.yaml\" --config-file \"config/api_config.config\" \n",
    "```\n",
    "\n",
    "### Output\n",
    "Running this line of code with the above described api_config.config example, will result in the following output:\n",
    "```\n",
    "{\"data\": [{\"text\": \"Happy 7th Anniversary, DARREN &amp; DARRENatics!\\n\\n7years of happiness even by simply looking at you or watching you.\\n\\nLove you then, love you now, love you always!\\n\\n#DarrenEspanto @Espanto2001\", \"created_at\": \"2021-05-31T23:23:33.000Z\", \"id\": \"1399506867999547392\", \"author_id\": \"2749743179\", \"public_metrics\": {\"retweet_count\": 15, \"reply_count\": 2, \"like_count\": 30, \"quote_count\": 0}}, \n",
    "(...)\n",
    "{\"id\": \"1399409079446081536\", \"public_metrics\": {\"retweet_count\": 0, \"reply_count\": 0, \"like_count\": 2, \"quote_count\": 0}, \"created_at\": \"2021-05-31T16:54:58.000Z\", \"text\": \"To Whom It May Concern:  All the people who tell you who you should or should not be, will never be there for you as much as you wish. Be whoever the hell makes you happy. If people don\\u2019t want you to achieve personal happiness/acceptance, why keep them around? #MutantFam\"}}], \n",
    "\n",
    "\"includes\": {\"users\": [{\"username\": \"ggr_mom\", \"description\": \"Certified DN since 2014 \\u2022 Follow DARREN\\u2019s Twitter @Espanto2001 \\u2022IG: @darrenespanto \\u2022YT: Darren Lyndon Espanto\\u2022 HOME RUN CONCERT 6.19.2021 \\ud83d\\udc9a New single: TAMA NA\", \"id\": \"2749743179\", \"name\": \"DarrenaticMom\"},\n",
    "(...)\n",
    "{\"username\": \"UselessKnwldge\", \"description\": \"Comedic reviews of horror with @arthurreturns Please subscribe. #HorrorFamily #MutantFam #TheLastDriveIn #HorrorReviews #HorrorPodcast\", \"id\": \"196303269\", \"name\": \"Useless Knowledge Casey\"}]},\n",
    "\n",
    "\"meta\": {\"newest_id\": \"1399506867999547392\", \"oldest_id\": \"1399409079446081536\", \"result_count\": 10, \"next_token\": \"b26v89c19zqg8o3foswucojbbx9lqiez94auwn10p55z1\"}}\n",
    "```\n",
    "\n",
    "### Saved format\n",
    "The output will be saved as:\n",
    "1. a dictionary, <filename_prefix>.json file\n",
    "2. a compact <filename_prefix>.csv file\n",
    "3. an unpacked and cleaned table <filename_prefix_cleaned>.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
