{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guideline to analyzig historical Twitter data\n",
    "\n",
    "To analyze historical Twitter data (i.e., all public Tweets from now to the first Tweet in March 2006), a number of steps have to be taken:\n",
    "\n",
    "1. Get an approved 'Academic Research' developer account\n",
    "2. Enter Bearer Token\n",
    "3. Determine your filter options\n",
    "4. Collect relevant tweets\n",
    "5. Analyze data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get an Academic Research developer account\n",
    "To get an account:\n",
    "\n",
    "1. Go to https://developer.twitter.com/en/solutions/academic-research\n",
    "2. Click on `Apply for an account`\n",
    "3. Click on `Start Academic Research application`\n",
    "4. Fill in the requested information (about your research)\n",
    "\n",
    "You should get a response within about 7 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Enter Bearer Token\n",
    "After you've been granted an academic research developer account, Twitter will provide you with some information that is unique to your account:\n",
    "* API Key\n",
    "* API Secret Key\n",
    "* Bearer Token\n",
    "* Access Token Secret\n",
    "\n",
    "For the following steps, you'll only need the **Bearer Token**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to connect with the Twitter server, you need to save this Bearer Token as an *environmental variable*. \n",
    "To do this, open your terminal and use the following code (depending on your device):\n",
    "\n",
    "* **Mac**: `export \"BEARER_TOKEN\"=\"<insert_bearer_token_here>\"`\n",
    "* **Windows**: `SET BEARER_TOKEN=<insert_bearer_token_here>`\n",
    "\n",
    "If this doesn't work, you can also run the following code inside your Python console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BEARER_TOKEN']='<insert_bearer_token_here>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Determine your filter options\n",
    "\n",
    "To filter out the Tweets that are relevant to your research, the code takes some 'filter options'. These options are:\n",
    "1) **query_params**: How do you want to filter the Tweets? <br>\n",
    "2) **output_dir**: In what folder do you want to save the extracted Tweets? <br>\n",
    "3) **output_file_name**: What name do you want to give the output file? <br>\n",
    "4) **output_csv**: Do you want to save the output file as .csv or as .json (default)? <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Query parameters\n",
    "**query_params** = `dictionary`\n",
    "\n",
    "There is an extensive list of arguments you can use to fine tune how you want to filter the Tweets. Some basic options are already listed in the `options.json` file, such as:\n",
    "* **query**: this is the most import argument as it specifies what the tweets will be filtered on (in this case the hashtag '#EurovisionAgain', being written in English, having a geo-location, and not being a retweet)\n",
    "* **max_results**: how many tweets do you want to extract?\n",
    "* **end_time**: most recent UTC timestamp to which the Tweets will be provided (format: `YYYY-MM-DDTHH:mm:ssZ`)\n",
    "* **expansions**: requests additional data objects that relate to the originally returned Tweets (in this case the geo-location of the tweet)\n",
    "* **tweet.fields**: which specific Tweet fields will be delivered in each returned Tweet object <br>\n",
    "\n",
    "For extra options have a look at: https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: to select English Tweets that mentioned #EurovisionAgain, have a geo location and was not a retweet.\n",
    "# Select the latest 100 Tweets up to now (no end_time), also extract their geo location\n",
    "# From selected tweets, show Tweet id, Author id, date it was created, the text of the Tweet, entities, and geo location\n",
    "{\n",
    " \"query\": \"#EurovisionAgain lang:en has:geo -is:retweet\",\n",
    " \"max_results\": 100,\n",
    " \"end_time\": \"\",\n",
    " \"expansions\": \"geo.place_id\",\n",
    " \"tweet.fields\": \"id,author_id,created_at,text,entities,geo\"\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Ouput directory\n",
    "**output_dir** = `string`\n",
    "\n",
    "This is the path to where the output file containing all extracted tweets, will be saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: to save the filtered Tweets in the folder 'output', use:\n",
    "\"output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Ouput file name\n",
    "`output_file_name`\n",
    "\n",
    "This is the name the output file containing all extracted tweets will get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: to save the filtered Tweets in a file named 'extracted_tweets', use:\n",
    "\"extracted_tweets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Output file type\n",
    "`output_csv`\n",
    "\n",
    "When this option is \"True\", the output file will be saved as a .csv file in the output directory. If this option is \"False\" (or left empty), the output file will be saved as a. json file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: if you want to save the extracted Tweets as .json file, use:\n",
    "False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Collect relevant Tweets\n",
    "\n",
    "Now that you've entered the Bearer Token as environmental variable and have determined how you want to filter the Tweets and where you want to save the results, you can run the code. To do so, you have to follow these steps:\n",
    "1) Open your terminal <br>\n",
    "2) Type the following code in one line:\n",
    "* python version: `python3` <br>\n",
    "* script you want to run: `current_search.py` or `full-archive-search.py`<br>\n",
    "* query parameters: `--query_params '{\"query\": \"#EurovisionAgain\", \"max_results\": 10}'` <br>\n",
    "* output directory: `--output_dir 'output'` <br>\n",
    "* output file name: `--output_file_name 'extracted_tweets'`<br>\n",
    "* output file type: `--output_csv False` <br>\n",
    "\n",
    "3) Hit Enter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, this will look like:\n",
    "\n",
    "`python3 full-archive-search.py --query_params '{\"query\": \"#EurovisionAgain\", \"max_results\": 10}' --output_dir 'output' --output_file_name 'extracted_tweets' --output_csv False`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze data\n",
    "\n",
    "### 5.1. Elasticsearch\n",
    "After you've extracted and saved the Tweets relevant to your research, you can analyze the data. For this, you need to load the data into Elasticsearch:\n",
    "1) Open Elasticsearch <br>\n",
    "2) ... <br>\n",
    "\n",
    "### 5.2. Kibana\n",
    "After you've uploaded the data, you can visualize it in Kibana:\n",
    "1) Open Kibana <br>\n",
    "2) ... <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
