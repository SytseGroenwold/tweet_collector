{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d60e5ea",
   "metadata": {},
   "source": [
    "# Search Tweets\n",
    "\n",
    "Twitter forms a rich source of information for researchers interested in studying 'the public conversation'.\n",
    "\n",
    "In order to find Tweets related to the topic of your interest, you may search tweets using two endpoints, **recent search** ,or **full-archive search**. A recent search will yield Tweets from the past 7 days, while the full-archive search goes back to the first public Tweet from March 2006. \n",
    "\n",
    "Please keep in your mind that **full-archive search is accessible only through the Academic Research product track.**\n",
    "\n",
    "To filter tweets, no matter which endpoint you are using, you need to provide a **search query**.\n",
    "According to the Twitter website, \"These search queries are created with a set of operators that match on Tweet and user attributes, such as message keywords, hashtags, and URLs. Operators can be combined into queries with boolean logic and parentheses to help refine the queries matching behavior.\" More on these queries later.\n",
    "\n",
    "In this guideline, we will describe how you can use the [tweet_collector repository](https://github.com/UtrechtUniversity/tweet_collector) to extract tweets for *your* research!\n",
    "\n",
    "\n",
    "**Note** In order to copy and paste text between your local computer and your workspace on cloud, you can save it in a .txt file and transfer it via SCP command.\n",
    "\n",
    "```sh\n",
    "    scp txt_to_copy.txt [Usernames@ip-address]:/txt_to_copy.txt\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed39d509",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "In order to search tweets using tweet_collector, you need to set the **endpoint**, **credentials**, and **configurations**.\n",
    "\n",
    "### 1. Endpoint\n",
    "By default, this library expects to find the endpoint in `config/.twitter_keys.yaml`. To make this file, run the following code in **Terminal**\n",
    "\n",
    "```\n",
    "cd tweet_collector\n",
    "mkdir config\n",
    "cd config\n",
    "touch .twitter_keys.yaml\n",
    "```\n",
    "#### 1.A. Recent Search\n",
    "To execute a recent search, the endpoint specification needs to be set to 'recent'. The ‘recent’ search endpoint provides Tweets from the **past 7 days**. To use recent search endpoint, copy the following code in `config/.twitter_keys.yaml`.\n",
    "\n",
    "\n",
    "```\n",
    "search_tweets_v2:\n",
    "  endpoint:  https://api.twitter.com/2/tweets/search/recent\n",
    "\n",
    "```\n",
    "\n",
    "#### 1.B. Full-archive Search\n",
    "To execute a full-archive search, the endpoint specification needs to be set to 'all'. This endpoint provides access to all publicly available Tweets posted **since March 2006**. To use the full-archive search endpoint, copy the following code in `config/.twitter_keys.yaml`.\n",
    "\n",
    "```\n",
    "search_tweets_v2:\n",
    "  endpoint:  https://api.twitter.com/2/tweets/search/all\n",
    "```\n",
    "\n",
    "\n",
    "### 2. Credentials\n",
    "The credential file holds your Twitter credentials. They can be set either as environment variables or in a yaml file that includes the endpoint. \n",
    "\n",
    "* The simplest credential file should look like this:\n",
    "```\n",
    "search_tweets_v2:\n",
    "  endpoint:  https://api.twitter.com/2/tweets/search/...\n",
    "  consumer_key: ek...\n",
    "  consumer_secret: hy...\n",
    "  bearer_token: AA...\n",
    "```\n",
    "* To set credentials as environment variables, run the following code in **Terminal**:\n",
    "```\n",
    "export consumer_key=[ek...]\n",
    "export consumer_secret=[hy...]\n",
    "export bearer_token=[AA...]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d8ad18",
   "metadata": {},
   "source": [
    "### 3. Configuration file\n",
    "The configuration file (i.e., `config/api_config.config`) generally contains three groups of elements: **search rules (including search query)**, **search paramters**, and **output paramters**. If a valid configuration file is found, all arguments will be populated from there. To make this file run the following code in **Terminal**\n",
    "\n",
    "```\n",
    "cd tweet_collector\n",
    "cd config\n",
    "touch api_config.config\n",
    "```\n",
    "\n",
    "An example of a config-file could be:\n",
    "\n",
    "```\n",
    "[search_rules]\n",
    "start_time = 2020-05-01\n",
    "end_time = 2021-06-01\n",
    "query = (happy or happiness) lang:en -birthday -is:retweet has:geo has:media\n",
    "tweet_fields = id,author_id,text,created_at\n",
    "place_fields = contained_within,country\n",
    "media_fields = type,preview_image_url\n",
    "expansions = geo.place_id,attachments.media_keys,author_id\n",
    "\n",
    "[search_params]\n",
    "results_per_call = 10\n",
    "max_tweets = 10\n",
    "output_format = r\n",
    "\n",
    "[output_params]\n",
    "save_file = True\n",
    "filename_prefix = output_new\n",
    "results_per_file = 10\n",
    "```\n",
    "\n",
    "In the following you can find more details about each section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7642dd",
   "metadata": {},
   "source": [
    "#### 3.A. Search rules\n",
    "As the name suggests, the `[search_rules]` should contain all search filters necessary for your research. \n",
    "\n",
    "##### Time/id filters\n",
    "To filter Tweets based on time/id, use one or more of the following search rules:\n",
    "```\n",
    "start_time = <Start of datetime window, format ‘YYYY-mm-DDTHH:MM’> \n",
    "end_time = <End of datetime window, format ‘YYYY-mm-DDTHH:MM’>\n",
    "since_id = <Tweet ID, will start search from Tweets after this one>\n",
    "until_id = <Tweet ID, will end search from Tweets before this one>\n",
    "```\n",
    "*Example: if you want to look back for relevant Tweets till may 2021, you can use `start_time = 2021-05-01`*\n",
    "\n",
    "##### Adding extra info\n",
    "To include extra information to your results, you can use various **'..._fields'** rules (see [this page](https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/user) for more info):\n",
    "```\n",
    "tweet_fields = <A comma-delimited list of Tweet JSON attributes to include in endpoint responses>\n",
    "place_fields = <A comma-delimited list of Twitter Place JSON attributes to include in endpoint responses>\n",
    "user_fields = <A comma-delimited list of User JSON attributes to include in endpoint responses>\n",
    "media_fields = <A comma-delimited list of media JSON attributes to include in endpoint responses>\n",
    "poll_fields = <A comma-delimited list of Twitter Place JSON attributes to include in endpoint responses>\n",
    "```\n",
    "*Example: if you want to know more about the geographical information of the filtered tweets, such as the country and country code, you can include `geo_fields = country,country_code`.*\n",
    "\n",
    "N.B. To be able to include (one of) these extra fields listed above, you also need to provide the **'expansions'** rule:\n",
    "```\n",
    "expansions = <A comma-delimited list of expansions. Specified expansions results in full objects in the ‘includes’ response object>\n",
    "```\n",
    "*Example: if you wish to include `geo_fields = country,country_code` you have to include `expansions = geo.place_id`. While the place ID will be located in the Tweet object, you will find this ID and all additional place fields in the 'includes' data object. (Please see [this page](https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/user) for ..._fields-expansions pairs.)*\n",
    "\n",
    "##### Search query\n",
    "Finally, the most import rule, is your search query:\n",
    "```\n",
    "query = <Search query>\n",
    "```\n",
    "In the query specification, you enter how you wish to filter Tweets. Commonly used arugments are:\n",
    "* `<key_word1> OR <key_word2>`: look for Tweets including either word1 or word2 *(Example: happy OR happiness finds Tweets with the words happy or happiness in them)*\n",
    "* `lang:<lang>`: only receive Tweets that are in specific langauge *(Example, lang:en selects only English Tweets)*\n",
    "* `-is:<type>`: '-' is a negation operator; excludes certain types of Tweets *(Example: -is:retweet exclused retweets, leaving only original Tweets)* \n",
    "* `-<key_word>`: '-' is a negation operator; excludes Tweets with key_word in it *(Example: -birthday excludes Tweets with 'birthday' in them)*\n",
    "* `has:<prop>`: matches Tweets that have specific property *(Example: has:geo selectes Tweets with Tweet-specific geolocation data provided by the Twitter user)*\n",
    "\n",
    "So, if you want to look for original Tweets in English related to happy or happiness containing at least one hashtag, but are not related to birthday whishes, we write:\n",
    "```\n",
    "query = (happy or happiness) lang:en -birthday -is:retweet has:hashtags\n",
    "```\n",
    "\n",
    "To get an extensive overview of how you can structure a query, have a look [here](https://developer.twitter.com/en/docs/twitter-api/tweets/counts/integrate/build-a-query). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1b6f11",
   "metadata": {},
   "source": [
    "#### 3.B. Search parameters\n",
    "Search parameters determine how the filtering is done and how the final output is structured.\n",
    "\n",
    "Here are some examples:\n",
    "```\n",
    "[search_params]\n",
    "results_per_call = <Number of results to return per call (default 10; max 100)>\n",
    "max_tweets = <Maximum number of Tweets to return for this session of requests>\n",
    "max_pages = <Maximum number of pages/API calls to use for this session>\n",
    "output_format = <Set output format*>\n",
    "extra_headers = <JSON-formatted str representing a dict of additional HTTP request headers>\n",
    "```\n",
    "*<br>\n",
    "‘r’ Unmodified API [R]esponses. (default). <br>\n",
    "‘a’ [A]tomic Tweets: Tweet objects with expansions inline. <br>\n",
    "‘m’ [M]essage stream: Tweets, expansions, and pagination metadata as a stream of messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df92fee9",
   "metadata": {},
   "source": [
    "#### 3.C. Output parameters\n",
    "The output parameters are the final step of the search; they describe if the output should be stored and how: \n",
    "\n",
    "```\n",
    "[output_params]\n",
    "save_file = True\n",
    "filename_prefix = <prefix for the filename where tweet json data will be stored>\n",
    "results_per_file = <Maximum tweets to save per file>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e45e22",
   "metadata": {},
   "source": [
    "## Run\n",
    "\n",
    "After you've filled in your endpoint and credentials in the `.twitter_keys.yaml`,and entered all parameters needed for your Twitter search in the `api_config.config` file, you can run the script in the command line with the following code:\n",
    "\n",
    "```\n",
    "cd tweet_collector\n",
    "python3 src/search_tweet.py --credential-file \"config/.twitter_keys.yaml\" --config-file \"config/api_config.config\" \n",
    "```\n",
    "\n",
    "By default, this library expects this file at `config/.twitter_keys.yaml`, but you can pass the relevant location as needed with the `--credential-file <CREDENTIAL_FILENAME>` flag for the command-line app. If you save the endpoint and credentials in another file, you need to change the previous steps accordingly.\n",
    "\n",
    "By default, this library expects this file at `config/api_config.config` but you can pass the relevant location as needed with the `--config-file <CONFIG_FILENAME>` flag for the command-line app. If you save the endpoint and credentials in another file, you need to change the previous steps accordingly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4074cd2",
   "metadata": {},
   "source": [
    "\n",
    "### Output\n",
    "Using the example `api_config.config` file as described in **3. Configuration file**, running the script will result in the following output:\n",
    "```\n",
    "{\n",
    "\"data\": \n",
    "[{\"author_id\": \"1198934425834336256\", \"text\": \"Who needs toys when you have a tail? Make your own happiness my friends. It doesnt take a partner, spouse,  health, fame or prosperity to be happy. All it takes to acceptance of who you are, courage to make changes and contentment with your life choices. Blessed Be\\ud83d\\udda4 https://t.co/1ei7183JZJ\", \"attachments\": {\"media_keys\": [\"7_1399491472374775818\"]}, \"id\": \"1399491656978665474\", \"geo\": {\"place_id\": \"dd9c503d6c35364b\"}, \"created_at\": \"2021-05-31T22:23:06.000Z\"}, \n",
    "(...)\n",
    "{\"author_id\": \"1213711645278523393\", \"text\": \"Happiness is free and it's for everyone.\\nNo color or race can stop you from being happy - you've got this! \\n\\nHow happy are you right now? \\n-\\n#secguo #supportlocal #adultoys #pleasureproducts #pleasurepoint #adultsonlyplease #onlyinamericaus #onlyinamerica\\n#sexeducation101 https://t.co/9p1MbopT1o\", \"attachments\": {\"media_keys\": [\"7_1394846524979351552\"]}, \"id\": \"1394846549838995460\", \"geo\": {\"place_id\": \"3d533362cdab8107\"}, \"created_at\": \"2021-05-19T02:45:07.000Z\"}], \n",
    "\n",
    "\"includes\": {\n",
    "\"media\": \n",
    "[{\"media_key\": \"7_1399491472374775818\", \"preview_image_url\": \"https://pbs.twimg.com/ext_tw_video_thumb/1399491472374775818/pu/img/nLOpphX9bBEq5Zaf.jpg\", \"type\": \"video\"},\n",
    "(...)\n",
    "{\"media_key\": \"7_1394846524979351552\", \"preview_image_url\": \"https://pbs.twimg.com/ext_tw_video_thumb/1394846524979351552/pu/img/05ldhAVdJiqyXN2S.jpg\", \"type\": \"video\"}],\n",
    "\n",
    "\"users\": \n",
    "[{\"id\": \"1198934425834336256\", \"name\": \"Phoenix \\ud83d\\udd1e\", \"username\": \"Steve96570671\"},\n",
    "(...)\n",
    "{\"id\": \"1213711645278523393\", \"name\": \"SECGUOOEJ\", \"username\": \"secguo\"}],\n",
    "\n",
    "\"places\": \n",
    "[{\"country\": \"Verenigde Staten\", \"full_name\": \"Pennsylvania, USA\", \"id\": \"dd9c503d6c35364b\"},\n",
    "(...)\n",
    "{\"country\": \"Verenigde Staten\", \"full_name\": \"Irvine, CA\", \"id\": \"3d533362cdab8107\"}]\n",
    "}\n",
    "\n",
    "\"meta\": \n",
    "{\"newest_id\": \"1399506867999547392\", \"oldest_id\": \"1399409079446081536\", \"result_count\": 10, \"next_token\": \"b26v89c19zqg8o3foswucojbbx9lqiez94auwn10p55z1\"}\n",
    "}\n",
    "```\n",
    "\n",
    "### Saved format\n",
    "The output will be saved as:\n",
    "1. a dictionary (i.e., the output printed above) <filename_prefix>.json file\n",
    "2. a compact <filename_prefix>.csv file\n",
    "3. an unpacked and cleaned table <filename_prefix_cleaned>.csv (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fccf4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
