{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34388aab",
   "metadata": {},
   "source": [
    "# Visualizing Twitter Data\n",
    "Once you've created a .json file with your filtered Tweets, the next (and final) step is to visualize this data. This final step is executed by means of Elasticsearch and Kibana. To do so, you have to perform a few actions.\n",
    "\n",
    "In this guideline we will walk you through the following steps:\n",
    "1. Running Elasticsearch and Kibana using **Docker**\n",
    "2. Loading the extracted tweets into **Elasticsearch**\n",
    "3. Visualizing the data in **Kibana**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb9bff",
   "metadata": {},
   "source": [
    "## 1. Docker\n",
    "\n",
    "### Installing Docker (Desktop/App)\n",
    "First, you need to install Docker. To install Docker, go to [this site](https://docs.docker.com/get-docker/). For example, to install Docker in the VRE, type the following commands in the command line within your VRE:\n",
    "\n",
    "```\n",
    "sudo apt update\n",
    "sudo apt upgrade\n",
    "sudo reboot\n",
    "sudo apt install docker.io\n",
    "```\n",
    "Once you've installed Docker, you can move on to the next step; running the Docker container. \n",
    "\n",
    "### Running the Docker container\n",
    "In the 'tweet_collector' repo is a `docker-compase.yaml` file. Using this file, you can run a Docker container that includes Elasticsearch and Kibana. To run this container, type the following code in the command line (N.B. within the 'tweet_collector' directory):\n",
    "\n",
    "```\n",
    "docker-compose up -d\n",
    "```\n",
    "\n",
    "If you've downloaded Docker App/Desktop, you can see that, under the tab 'containers/apps' there is now a 'tweet_collector' app and it's running. When you click on the play button before 'tweet_collector' a roll out menu appears. There are two sub categories; `es-container` and `kb-container`. When you click on 'open in browser' for kb-container, a new web page will open. This brings us to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a411aadc",
   "metadata": {},
   "source": [
    "## 2. Elasticsearch\n",
    "In this newly open web page, you see on overview of various actions, among which `Kibana visualize & analyze`. Before you can visualize your tweets, you first need to load the data into Elastic.\n",
    "\n",
    "### Loading data\n",
    "To add your data into Elastic, you need to run the following code in your command line terminal (within the 'tweet_collector' directory):\n",
    "\n",
    "```\n",
    "python src/load_elastic.py <path_to_output_file>\n",
    "```\n",
    "For example, when you want to read *'name_0.json'* within the output folder, you run *python src/load_elastic.py output/name_0.json*. This will return a message with \"Loaded n tweets into Elasticsearch\" (with n being the value you added as results_per_call).\n",
    "\n",
    "However, depending on your configuration settings, the `search_tweet.py` script (see guideline 2) can also yield more than one .json file (for example if you extract more tweets than your 'results_per_file' variable). To be able to load in all data files (name_X.json), run the same line but exclude the numbers:\n",
    "\n",
    "```\n",
    "python src/load_elastic.py output/name.json\n",
    "```\n",
    "\n",
    "The script will then search for all files in the directory you specified (output) with the name (name*.json).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039992b6",
   "metadata": {},
   "source": [
    "## 3. Kibana\n",
    "### Adding data in Kibana\n",
    "Now, when you click on `Kibana visualize & analyze` you can add the imported data. To do this, perform the following steps:\n",
    "\n",
    "1. Click on `Add your data`\n",
    "2. Click on `Create index pattern`\n",
    "3. Provide an index pattern name, in this case *twitter*, and click `Next step`\n",
    "4. Select time field (e.g., 'data.created_at') or chose 'I don't want to use the time filter'\n",
    "5. Click `Create index pattern`\n",
    "6. The final step is an overview of the imported data and it's mapping/type structure.\\* You don't need to change anything.\n",
    "\n",
    "\\*This based on the `config/mapping_twitter_tweet.json` file used in the `load_elastic.py` script.\n",
    "\n",
    "### Creating a dashboard\n",
    "To create a visualization of the twitter data, you can go to the home page by clicking in the upper left corner on the `elastic` icon. Now when you click on `Kibana visualize & analyze`, you see an overview of possible visualizations you can make. For example, you can create a dashboard. When you click on `Dashboard`, you get to a screen with `Create new dashboard`. After this, you can add panels to your dashboard with `Create panel`. Another screen with multiple new visualization options appears. When you click on `Lens`, you can create various graphs.\n",
    "\n",
    "By dragging fields to the center of the screen, you can create graphs. You can personalize the graphs by means of form (e.g., stacked bar, area, bar, etc.) and by defining `Break down by`, splitting up your graph even further. \n",
    "\n",
    "N.B. When you've added a time field (see step 4), make sure to select the right timeframe (see calender icon on the right of the screen) matching your Twitter filter. The default value of this 'time filter' is '15 minutes ago - now'. So, for example, if you've filtered tweets untill a certain end date (that is before 15 minutes ago), this will leave you with an empty list of `Available fields`.\n",
    "\n",
    "For more information about what you can do with Kibana, have a look at [this web page](https://www.elastic.co/guide/en/kibana/current/discover.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e3074",
   "metadata": {},
   "source": [
    "## 4. Saving data\n",
    "As you are working on a virtual research environment, it is essential to save all your data on another location before closing off the environment.\n",
    "\n",
    "### Saving twitter data\n",
    "To ensure you've saved all the extracted tweets, make sure to save the output .json file.\n",
    "\n",
    "### Saving visuals\n",
    "The visuals you've created can either be saved as:\n",
    "* a csv (see button `Download as CSV`, which translates your graph/visualization into a table in csv format).\n",
    "* an image (by right clicking on the created visual, you can save the visual as image)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
